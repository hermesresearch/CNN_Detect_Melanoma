{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "gpuType": "V100",
      "cell_execution_strategy": "setup",
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOO/FE4kh38ZqQMwROsJA1H",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hermesresearch/CNN_Detect_Melanoma/blob/main/Joseph_hanna_nn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Problem Statement:\n",
        "The objective of this project is to develop a custom convolutional neural network (CNN) model for accurate detection of melanoma, a deadly form of skin cancer. Melanoma accounts for 75% of skin cancer deaths and early detection is crucial for effective treatment. The proposed solution aims to automate the evaluation of skin images and alert dermatologists about the presence of melanoma, thereby reducing the manual effort required for diagnosis.\n",
        "\n",
        "Dataset Description:\n",
        "The dataset used for this project can be downloaded from [link to the dataset]. It comprises a collection of 2357 images representing both malignant and benign oncological diseases. The dataset was obtained from the International Skin Imaging Collaboration (ISIC). The images have been categorized based on the classification provided by ISIC, with an approximately equal number of images in most subsets, except for melanomas and moles, which have a slightly larger representation.\n",
        "\n",
        "The dataset includes the following diseases:\n",
        "1. Actinic keratosis\n",
        "2. Basal cell carcinoma\n",
        "3. Dermatofibroma\n",
        "4. Melanoma\n",
        "5. Nevus\n",
        "6. Pigmented benign keratosis\n",
        "7. Seborrheic keratosis\n",
        "8. Squamous cell carcinoma\n",
        "9. Vascular lesion\n",
        "\n"
      ],
      "metadata": {
        "id": "GwRhzJM_sv7a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Project Pipeline\n",
        "\n",
        "\n",
        "Data Reading & Understanding:\n",
        "\n",
        "Define paths for train and test images.\n",
        "Dataset Creation:\n",
        "\n",
        "Create train and validation datasets.\n",
        "Resize images to 180x180 pixels.\n",
        "Dataset Visualization:\n",
        "\n",
        "Visualize one instance of each class in the dataset.\n",
        "Model Building & Training:\n",
        "\n",
        "Create a CNN model to detect the nine classes.\n",
        "Rescale images between 0 and 1.\n",
        "Choose optimizer and loss function.\n",
        "Train the model for approximately 20 epochs.\n",
        "Data Augmentation:\n",
        "\n",
        "Apply data augmentation techniques to address underfitting/overfitting.\n",
        "Model Building & Training on Augmented Data:\n",
        "\n",
        "Build a CNN model on augmented data.\n",
        "Train the model for approximately 20 epochs.\n",
        "Class Distribution Analysis:\n",
        "\n",
        "Examine the class distribution in the training dataset.\n",
        "Identify the class with the least number of samples.\n",
        "Determine classes dominating the dataset.\n",
        "Handling Class Imbalances:\n",
        "\n",
        "Use Augmentor library to rectify class imbalances.\n",
        "Model Building & Training on Rectified Data:\n",
        "\n",
        "Build a CNN model on the rectified data.\n",
        "Train the model for approximately 30 epochs.\n",
        "Findings & Evaluation:\n",
        "\n",
        "Evaluate model performance and check for overfitting/underfitting."
      ],
      "metadata": {
        "id": "VZaaGcG9FwmO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "we366J7PsrRK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pathlib\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from glob import glob\n",
        "import PIL\n",
        "import numpy as np\n",
        "# TensorFlow\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import BatchNormalization, Dense, Dropout, Activation, Flatten, Conv2D, MaxPool2D\n",
        "from tensorflow.keras.layers.experimental.preprocessing import Rescaling\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras.utils import to_categorical\n"
      ],
      "metadata": {
        "id": "Rvue6GFmX-W5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Reading & Understanding:\n",
        "\n"
      ],
      "metadata": {
        "id": "5EJn88hmYb_N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive to the Colab notebook\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "VIg5v-T_b4TB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the paths for the training and testing datasets\n",
        "## Todo: Update the paths of the training and testing datasets\n",
        "\n",
        "path_folder = '/content/gdrive/MyDrive/CNN/Skin_Cancer_Data'\n",
        "train_data = pathlib.Path(path_folder + '/Train')\n",
        "test_data = pathlib.Path(path_folder + '/Test')"
      ],
      "metadata": {
        "id": "k3dSyJcreIMD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# List all files/directories in the path\n",
        "print(os.listdir(train_data))\n",
        "print(os.listdir(test_data))\n"
      ],
      "metadata": {
        "id": "KaB_jW_3eLDC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Counting the number of images in the training dataset\n",
        "count_train = len(list(train_data.glob('*/*.jpg')))\n",
        "print(count_train)\n",
        "# Counting the number of images in the testing dataset\n",
        "count_test = len(list(test_data.glob('*/*.jpg')))\n",
        "print(count_test)"
      ],
      "metadata": {
        "id": "8HzdKeD3fDbi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the batch size to 32\n",
        "# Set the image height and width to 180 pixels\n",
        "batch_size = 32\n",
        "img_height = 180\n",
        "img_width = 180"
      ],
      "metadata": {
        "id": "I4wWsUkMgXG_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a TensorFlow dataset for training images\n",
        "\n",
        "ds_train = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  train_data,\n",
        "  validation_split=0.2,\n",
        "  subset=\"training\",\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ],
      "metadata": {
        "id": "KfVLGlgjgbbn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a TensorFlow dataset for validation images\n",
        "ds_validation = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  train_data,\n",
        "  validation_split=0.2,\n",
        "  subset=\"validation\",\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ],
      "metadata": {
        "id": "GZoXh3BSgdbX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a TensorFlow dataset for the testing images\n",
        "ds_test = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  test_data,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ],
      "metadata": {
        "id": "QAVWOcBigjy2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the class names of skin cancer and store them in a list\n",
        "# The class names can be found in the 'class_names' attribute of the datasets\n",
        "# The class names correspond to the directory names in alphabetical order\n",
        "\n",
        "class_names = ds_train.class_names\n",
        "print(class_names)"
      ],
      "metadata": {
        "id": "Xuk0WgJ-gl_n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a figure with a size of 10x10 inches\n",
        "# Iterate over the first batch of images and labels in the training dataset\n",
        "# Iterate over the first 9 images in the batch\n",
        "# Create a subplot with 3 rows, 3 columns, and the current index\n",
        "# Display the image as a numpy array of type \"uint8\"\n",
        "# Set the title of the subplot as the corresponding class name from the \"class_names\" list\n",
        "# Disable the axis lines and labels for better visualization\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "for images, labels in ds_train.take(1):\n",
        "  for i in range(9):\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "    plt.title(class_names[labels[i]])\n",
        "    plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "40tZNYxKgoD_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cache, shuffle, and prefetch the training dataset\n",
        "# Cache and prefetch the validation dataset\n",
        "\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "ds_train = ds_train.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
        "ds_validation = ds_validation.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "metadata": {
        "id": "xrg3UFBDgq6P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessing_layers = [\n",
        "    tf.keras.layers.experimental.preprocessing.Rescaling(1./255, input_shape=(180, 180, 3))\n",
        "]"
      ],
      "metadata": {
        "id": "kL2sOQatg-ni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Rescale the input images to a range of [0, 1]\n",
        "# Convolutional layers with 32 filters, kernel size of (3, 3), and ReLU activation\n",
        "# Convolutional layers with 64 filters, kernel size of (3, 3), and ReLU activation\n",
        "# Convolutional layers with 128 filters, kernel size of (3, 3), and ReLU activation\n",
        "# Flatten the output from previous layers\n",
        "# Dense (fully connected) layer with 512 units and ReLU activation\n",
        "\n",
        "# Output layer with 1 unit and sigmoid activation for binary classification\n",
        "# Set the number of classes to 9\n",
        "\n",
        "input_shape = (180,180,3)\n",
        "lr = 1e-5\n",
        "init = 'normal'\n",
        "activ = 'relu'\n",
        "\n",
        "model = Sequential()\n",
        "model.add(tf.keras.layers.experimental.preprocessing.Rescaling(1./255, input_shape=(180, 180, 3)))\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
        "model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1))\n",
        "model.add(Activation('sigmoid'))\n",
        "\n",
        "# Note: The model as currently defined is a binary classifier, not a multi-class classifier\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "-iGaqYBLhYq1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model with the specified optimizer, loss function, and metrics\n",
        "\n",
        "\n",
        "optimizer = 'adam'\n",
        "loss_fn = \"binary_crossentropy\"\n",
        "model.compile(optimizer=optimizer,\n",
        "              loss=loss_fn,\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "3ga1qtpThbwd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# View the summary\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "odIpCHFxhe69"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model on the training dataset while validating on the validation dataset\n",
        "\n",
        "epochs = 20\n",
        "batch_size = 32\n",
        "\n",
        "history = model.fit(\n",
        "  ds_train,\n",
        "  batch_size=batch_size,\n",
        "  validation_data=ds_validation,\n",
        "  epochs=epochs\n",
        ")"
      ],
      "metadata": {
        "id": "jbv5bkZ3hghl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Plotting training and validation accuracy\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Accuracy')\n",
        "\n",
        "# Plotting training and validation loss\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Loss')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "xoaZwcyNhlUW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the training dataset\n",
        "\n",
        "loss, accuracy = model.evaluate(ds_train, verbose=1,)\n",
        "# Evaluate the model on the validation dataset\n",
        "\n",
        "loss_v, accuracy_v = model.evaluate(ds_validation, verbose=1)\n",
        "# Print the evaluation results\n",
        "print(\"Accuracy: \", accuracy)\n",
        "print(\"Validation Accuracy: \",accuracy_v)\n",
        "print(\"Loss: \",loss)\n",
        "print(\"Validation Loss\", loss_v)\n",
        "\n"
      ],
      "metadata": {
        "id": "qgj3ptbYhqx9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# The model's performance on both the training and validation datasets is evaluated.\n",
        "# However, the provided loss values (-80029597696.0 and -81044750336.0) seem to be unusually large and negative,\n",
        "# which indicates that there might be an issue with the model or the evaluation process.\n",
        "# Similarly, the obtained accuracy values (0.12077402323484421 and 0.12906096875667572) are relatively low,\n",
        "# suggesting that the model is not performing well in terms of accuracy on both datasets.\n",
        "# Further investigation is needed to identify and address any potential issues."
      ],
      "metadata": {
        "id": "U7u4d-d_0Ko6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an instance of ImageDataGenerator for data augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "        featurewise_center=False,\n",
        "        samplewise_center=False,\n",
        "        featurewise_std_normalization=False,\n",
        "        samplewise_std_normalization=False,\n",
        "        zca_whitening=False,\n",
        "        rotation_range=10,\n",
        "        zoom_range = 0.1,\n",
        "        width_shift_range=0.1,\n",
        "        height_shift_range=0.1,\n",
        "        horizontal_flip=False,\n",
        "        vertical_flip=False)\n",
        "\n",
        "image_class = ['nevus','melanoma','basal_cell_caricoma','actinic_keratosis','vasc_lesion','dermatofibroma', 'pigmented_keratosis', 'seborrheic_keratosis', 'squamous_carci']\n",
        "\n",
        "train_batches = datagen.flow_from_directory(train_data,\n",
        "    target_size = (180,180),\n",
        "    classes = image_class,\n",
        "    batch_size = 64\n",
        " )\n",
        "\n",
        "valid_batches = datagen.flow_from_directory(test_data,\n",
        "    target_size = (180,180),\n",
        "    classes = image_class,\n",
        "    batch_size = 64\n",
        ")"
      ],
      "metadata": {
        "id": "WvWhupCvh0Kl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a figure with a size of 10x10 inches\n",
        "import matplotlib.pyplot as plt\n",
        "# Iterate over the first batch of images and labels in the training dataset\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "for images, labels in ds_train.take(1):\n",
        "# Create a subplot with 3 rows, 3 columns, and the current index\n",
        "# Display the image as a numpy array of type \"uint8\"\n",
        "  for i in range(9):\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "    plt.title(class_names[labels[i]])\n",
        "    plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "xJRt1vgmlaUX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model architecture\n",
        "# Convolutional layers with 32 filters, kernel size of (3, 3), ReLU activation, and 'same' padding\n",
        "# Max pooling layer with pool size (2, 2)\n",
        "# Dropout layer with a rate of 0.25\n",
        "# Convolutional layers with 64 filters, kernel size of (3, 3), ReLU activation, and 'same' padding\n",
        "# Max pooling layer with pool size (2, 2)\n",
        "# Dropout layer with a rate of 0.4\n",
        "# Convolutional layer with 128 filters, kernel size of (3, 3), and ReLU activation\n",
        "# Max pooling layer with pool size (2, 2)\n",
        "# Dropout layer with a rate of 0.5\n",
        "# Dense (fully connected) layer with 9 units and softmax activation for multi-class classification\n",
        "# Print the summary of the model architecture\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same', input_shape=input_shape))\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "\n",
        "model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', padding = 'Same'))\n",
        "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', padding = 'Same'))\n",
        "model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(9, activation='softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "P-NhrvSYldDB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import legacy\n",
        "# Create an instance of the Adam optimizer with custom parameters\n",
        "\n",
        "optimizer = legacy.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
        "# Compile the model with categorical cross-entropy loss, the custom optimizer, and accuracy metric\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizer,\n",
        "              metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "8jkkV0cNlfo2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an instance of the ReduceLROnPlateau callback\n",
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy',\n",
        "    patience=3,\n",
        "    verbose=1,\n",
        "    factor=0.5,\n",
        "    min_lr=0.00001)"
      ],
      "metadata": {
        "id": "mqVEVq7xlh6W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model using the training data batches\n",
        "\n",
        "epochs = 20\n",
        "batch_size = 10\n",
        "history = model.fit(train_batches,\n",
        "  epochs = epochs, verbose = 1, validation_data=valid_batches , callbacks=[learning_rate_reduction])"
      ],
      "metadata": {
        "id": "rlTzMWxhlj3O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Retrieve the accuracy values from the training history\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "# Print the available keys in the history object\n",
        "\n",
        "print(history.history.keys, \":\")\n",
        "# Retrieve the validation accuracy values from the training history\n",
        "\n",
        "val_acc = history.history['val_accuracy']\n",
        "# Retrieve the loss values from the training history\n",
        "\n",
        "loss = history.history['loss']\n",
        "# Retrieve the validation loss values from the training history\n",
        "\n",
        "val_loss = history.history['val_loss']\n",
        "# Create a range of epochs\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "# Create a figure with subplots for accuracy and loss visualization\n",
        "# Plot the training and validation accuracy over epochs\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "C0gFPX5rll8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a sequential model\n",
        "    # Convolutional layer with 32 filters, kernel size of (3, 3), and ReLU activation\n",
        "    # Max pooling layer with pool size (2, 2)\n",
        "    # Convolutional layer with 64 filters, kernel size of (3, 3), and ReLU activation\n",
        "    # Max pooling layer with pool size (2, 2)\n",
        "    # Flatten the output from the previous layers\n",
        "    # Dense (fully connected) layer with 512 units and ReLU activation\n",
        "    # Dense (fully connected) layer with 9 units and softmax activation for multi-class classification\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(180, 180, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dense(9, activation='softmax')\n",
        "])\n"
      ],
      "metadata": {
        "id": "J0KLyOo80r7c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove the last layer from the model\n",
        "\n",
        "model.pop()\n",
        "# Add a new dense layer with 10 units and softmax activation\n",
        "\n",
        "\n",
        "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n"
      ],
      "metadata": {
        "id": "DMgqlMtb0sYU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model with the Adam optimizer, sparse categorical cross-entropy loss, and accuracy metric\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "f-bLRP7b0stC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "# Evaluate the model on the training dataset and obtain the loss and accuracy\n",
        "\n",
        "# Evaluate the model on the validation dataset and obtain the loss and accuracy\n",
        "\n",
        "loss, accuracy = model.evaluate(ds_train, verbose=1,)\n",
        "loss_v, accuracy_v = model.evaluate(ds_validation, verbose=1)\n",
        "\n",
        "print(\"Accuracy: \", accuracy)\n",
        "print(\"Validation Accuracy: \",accuracy_v)\n",
        "print(\"Loss: \",loss)\n",
        "print(\"Validation Loss\", loss_v)\n"
      ],
      "metadata": {
        "id": "8BaMzMq_lt02"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "aa4LC9jlyx1s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create a dictionary to store the count of images per class\n",
        "data = {}\n",
        "\n",
        "# Initialize the dictionary with empty lists for each class\n",
        "for i in class_names:\n",
        "    data[i] = []\n",
        "\n",
        "# Create a figure for plotting\n",
        "plt.figure(figsize=(5, 5))\n",
        "\n",
        "# Iterate over the training dataset and collect images for each class\n",
        "for images, labels in ds_train:\n",
        "    for i in range(9):\n",
        "        # Append the image to the respective class in the data dictionary\n",
        "        data[class_names[labels[i]]].append(images[i].numpy().astype(\"uint8\"))\n",
        "\n",
        "# Count the number of images in each class\n",
        "for i in data:\n",
        "    data[i] = len(data[i])\n",
        "\n",
        "# Create a bar plot to visualize the image count per class\n",
        "f = plt.figure()\n",
        "f.set_figwidth(5)\n",
        "f.set_figheight(5)\n",
        "\n",
        "plt.bar(range(len(data)), list(data.values()), align='center')\n",
        "plt.xticks(range(len(data)), list(data.keys()))\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ZADIJKJuluX-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zZKWD4Lhlx72"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "pip install Augmentor"
      ],
      "metadata": {
        "id": "JYdKx1Vm0ax3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TlTse0qs0bb0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import Augmentor\n",
        "# Iterate over the class names\n",
        "\n",
        "path_to_training_dataset=\"/content/gdrive/MyDrive/CNN/Skin_Cancer_Data/Train/\"\n",
        "    # Create an Augmentor pipeline for each class using the path to the training dataset\n",
        "    # Apply rotation augmentation with a probability of 0.7 and maximum rotation angles of 10 degrees\n",
        "    # Generate and save 500 augmented images for each class\n",
        "\n",
        "for i in class_names:\n",
        "    p = Augmentor.Pipeline(path_to_training_dataset + i)\n",
        "    p.rotate(probability=0.7, max_left_rotation=10, max_right_rotation=10)\n",
        "    p.sample(500)"
      ],
      "metadata": {
        "id": "XkCpotgKl1m5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count the number of images in the training dataset\n",
        "count_train = len(list(train_data.glob('*/output/*.jpg')))\n",
        "# Print the total count of images in the training dataset\n",
        "\n",
        "print(count_train)"
      ],
      "metadata": {
        "id": "KSLk0cR3l57t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import os\n",
        "\n",
        "# Create a list of file paths matching the pattern '*/*/output/*.jpg' in the training dataset directory\n",
        "path_list = [x for x in glob.glob(os.path.join(train_data, '*','output', '*.jpg'))]\n",
        "\n",
        "# Print the list of file paths\n",
        "print(path_list)\n"
      ],
      "metadata": {
        "id": "KGoMoszDl6be"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Create a list of lesion names by extracting the directory names from the file paths\n",
        "lesion_list_new = [os.path.basename(os.path.dirname(os.path.dirname(y))) for y in glob.glob(os.path.join(train_data, '*','output', '*.jpg'))]\n",
        "\n",
        "# Print the list of lesion names\n",
        "print(lesion_list_new)\n"
      ],
      "metadata": {
        "id": "daSsuZiq4Gbo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a dictionary that maps file paths to corresponding lesion names\n",
        "dataframe_dict_new = dict(zip(path_list, lesion_list_new))\n",
        "\n",
        "# Print the dictionary\n",
        "print(dataframe_dict_new)\n"
      ],
      "metadata": {
        "id": "si1pN_Sgl7yF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Create a DataFrame from the dictionary with columns 'Path' and 'Label'\n",
        "df2 = pd.DataFrame(list(dataframe_dict_new.items()), columns=['Path', 'Label'])\n",
        "\n",
        "# Assign the DataFrame to a new variable\n",
        "new_df = df2\n"
      ],
      "metadata": {
        "id": "T2SLpHF5mFBF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count the occurrences of each unique value in the 'Label' column of the DataFrame\n",
        "label_counts = new_df['Label'].value_counts()\n",
        "\n",
        "# Print the value counts\n",
        "print(label_counts)\n"
      ],
      "metadata": {
        "id": "77wL37t_mGWF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the batch size for training and evaluation\n",
        "batch_size = 32\n",
        "\n",
        "# Set the image height and width dimensions\n",
        "img_height = 180\n",
        "img_width = 180\n"
      ],
      "metadata": {
        "id": "QyHIzNFlmJTl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Set the directory path to the training dataset\n",
        "train_data = \"/content/gdrive/MyDrive/CNN/Skin_Cancer_Data/Train\"\n",
        "\n",
        "# Create a training dataset using the image_dataset_from_directory function\n",
        "ds_train = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    train_data,\n",
        "    seed=123,\n",
        "    validation_split=0.2,\n",
        "    subset='training',\n",
        "    image_size=(img_height, img_width),\n",
        "    batch_size=batch_size\n",
        ")\n"
      ],
      "metadata": {
        "id": "Ma7-0X7MmK5F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Create a validation dataset using the image_dataset_from_directory function\n",
        "ds_validation = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    train_data,\n",
        "    seed=123,\n",
        "    validation_split=0.2,\n",
        "    subset='validation',\n",
        "    image_size=(img_height, img_width),\n",
        "    batch_size=batch_size\n",
        ")\n"
      ],
      "metadata": {
        "id": "gKc5PNwKmMn9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPool2D, BatchNormalization, Dropout, Flatten, Dense\n",
        "\n",
        "# Create a Sequential model\n",
        "model = Sequential()\n",
        "\n",
        "# Add the first Conv2D layer with 32 filters, kernel size (3, 3), ReLU activation, padding 'same', and input shape\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same', input_shape=input_shape))\n",
        "# Add another Conv2D layer with 32 filters and ReLU activation\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "\n",
        "# Add MaxPooling layer with pool size (2, 2)\n",
        "model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "# Add BatchNormalization layer\n",
        "model.add(BatchNormalization())\n",
        "# Add Dropout layer with a rate of 0.25\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# Add another Conv2D layer with 64 filters, kernel size (3, 3), ReLU activation, and padding 'same'\n",
        "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "# Add another Conv2D layer with 64 filters and ReLU activation\n",
        "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "\n",
        "# Add MaxPooling layer with pool size (2, 2)\n",
        "model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "# Add BatchNormalization layer\n",
        "model.add(BatchNormalization())\n",
        "# Add Dropout layer with a rate of 0.4\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "# Add another Conv2D layer with 128 filters, kernel size (3, 3), and ReLU activation\n",
        "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
        "# Add BatchNormalization layer\n",
        "model.add(BatchNormalization())\n",
        "# Add MaxPooling layer with pool size (2, 2)\n",
        "model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "# Add Dropout layer with a rate of 0.4\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "# Flatten the previous layer outputs\n",
        "model.add(Flatten())\n",
        "\n",
        "# Add a Dense layer with 128 units and ReLU activation\n",
        "model.add(Dense(128, activation='relu'))\n",
        "# Add BatchNormalization layer\n",
        "model.add(BatchNormalization())\n",
        "# Add Dropout layer with a rate of 0.5\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# Add the final Dense layer with 1 unit and softmax activation\n",
        "model.add(Dense(1, activation='softmax'))\n",
        "\n",
        "# Print the model summary\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "rp_G5ksOmOL9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "W0PpNYTKmQGl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "PO26BUKZIf5L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model with the specified optimizer, loss function, and metrics\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "#### Here\n"
      ],
      "metadata": {
        "id": "lExp-8ZBIjhY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "# Set the batch size, image dimensions, and number of epochs\n",
        "batch_size = 10\n",
        "img_height = 180\n",
        "img_width = 180\n",
        "epochs = 50\n",
        "\n",
        "# Set the directory path to the training dataset\n",
        "train_data = \"/content/gdrive/MyDrive/CNN/Skin_Cancer_Data/Train\"\n",
        "\n",
        "# Create a training dataset using the image_dataset_from_directory function\n",
        "ds_train = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    train_data,\n",
        "    seed=123,\n",
        "    validation_split=0.2,\n",
        "    subset='training',\n",
        "    image_size=(img_height, img_width),\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "# Create a validation dataset using the image_dataset_from_directory function\n",
        "ds_validation = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    train_data,\n",
        "    seed=123,\n",
        "    validation_split=0.2,\n",
        "    subset='validation',\n",
        "    image_size=(img_height, img_width),\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "# Set the buffer size for dataset prefetching\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "# Cache and prefetch the training dataset\n",
        "ds_train = ds_train.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "# Cache and prefetch the validation dataset\n",
        "ds_validation = ds_validation.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "# Define a learning rate reduction callback\n",
        "learning_rate_reduction = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "    monitor='val_accuracy',\n",
        "    patience=3,\n",
        "    verbose=1,\n",
        "    factor=0.5,\n",
        "    min_lr=0.00001\n",
        ")\n",
        "\n",
        "# Train the model on the training dataset\n",
        "history = model.fit(\n",
        "    ds_train,\n",
        "    epochs=epochs,\n",
        "    verbose=1,\n",
        "    validation_data=ds_validation,\n",
        "    callbacks=[learning_rate_reduction]\n",
        ")\n"
      ],
      "metadata": {
        "id": "C6kk-VyL5yGG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "26sSnAjomTmV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Get the output layer of the model\n",
        "output_layer = model.layers[-1]\n",
        "num_output_neurons = output_layer.units\n",
        "print(f'Number of output neurons: {num_output_neurons}')\n",
        "\n",
        "# Get the activation function of the output layer\n",
        "output_activation = output_layer.activation.__name__\n",
        "print(f'Activation function of the output layer: {output_activation}')\n",
        "\n",
        "# Check the shape of the labels in the training dataset\n",
        "sample_batch = next(iter(ds_train))\n",
        "images, labels = sample_batch\n",
        "label_shape = labels.shape\n",
        "print(f'Shape of the labels: {label_shape}')\n",
        "\n",
        "# Check the shape of the images in the training dataset\n",
        "image_shape = images.shape\n",
        "print(f'Shape of the images: {image_shape}')\n",
        "\n",
        "# Check the expected input shape of the model\n",
        "input_shape = model.input_shape\n",
        "print(f'Expected input shape of the model: {input_shape}')\n",
        "\n"
      ],
      "metadata": {
        "id": "j6vX-XcvHFCK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fu3Qmn1ymVVd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "batch_size = 10\n",
        "img_height = 180\n",
        "img_width = 180\n",
        "epochs = 50\n",
        "\n",
        "train_data = \"/content/gdrive/MyDrive/CNN/Skin_Cancer_Data/Train\"\n",
        "\n",
        "ds_train = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  train_data,\n",
        "  seed=123,\n",
        "  validation_split=0.2,\n",
        "  subset='training',\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)\n",
        "\n",
        "ds_validation = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  train_data,\n",
        "  seed=123,\n",
        "  validation_split=0.2,\n",
        "  subset='validation',\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)\n",
        "\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "ds_train = ds_train.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "ds_validation = ds_validation.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "# Adjust the loss function and activation function\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "learning_rate_reduction = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy',\n",
        "    patience=3,\n",
        "    verbose=1,\n",
        "    factor=0.5,\n",
        "    min_lr=0.00001)\n",
        "\n",
        "history = model.fit(ds_train,\n",
        "  epochs=epochs,\n",
        "  verbose=1,\n",
        "  validation_data=ds_validation,\n",
        "  callbacks=[learning_rate_reduction])\n"
      ],
      "metadata": {
        "id": "bfJ-qATQmXo8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GjGB4LX0Cd1H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Get the accuracy and loss values from the history object\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "# Plot the training and validation accuracy\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "# Plot the training and validation loss\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "4q8f_og6Byfq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dir = \"/content/gdrive/MyDrive/CNN?Skin_Cancer_Data/Test\"\n",
        "\n",
        "ds_test = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    test_dir,\n",
        "    seed=123,\n",
        "    image_size=(img_height, img_width),\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "# Preprocess the test dataset\n",
        "ds_test = ds_test.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "# Evaluate the model on the test dataset\n",
        "test_loss, test_accuracy = model.evaluate(ds_test)\n",
        "\n",
        "print(\"Test Loss:\", test_loss)\n",
        "print(\"Test Accuracy:\", test_accuracy)\n"
      ],
      "metadata": {
        "id": "SaOqNysUCfhD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# List all files/directories in the train directory\n",
        "print(os.listdir(train_data))\n",
        "\n",
        "# List all files/directories in the test directory\n",
        "print(os.listdir(test_data))\n"
      ],
      "metadata": {
        "id": "tXS2NKIFD7XA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "# Define the class names\n",
        "class_names = ['actinic keratosis', 'seborrheic keratosis', 'basal cell carcinoma', 'nevus', 'squamous cell carcinoma', 'vascular lesion', 'dermatofibroma', 'pigmented benign keratosis', 'melanoma']\n",
        "\n",
        "# Path to the directory containing the test images\n",
        "test_data_dir = \"/content/gdrive/MyDrive/CNN/Skin_Cancer_Data/Test/melanoma\"\n",
        "\n",
        "# List all the image filenames in the directory\n",
        "image_files = os.listdir(test_data_dir)\n",
        "\n",
        "# Choose a random image from the directory\n",
        "random_image_file = random.choice(image_files)\n",
        "\n",
        "# Load the image and preprocess it\n",
        "img_path = os.path.join(test_data_dir, random_image_file)\n",
        "img = image.load_img(img_path, target_size=(img_height, img_width))\n",
        "img_array = image.img_to_array(img)\n",
        "img_array = np.expand_dims(img_array, axis=0)\n",
        "img_array /= 255.0  # Normalize the image\n",
        "\n",
        "# Make predictions using the trained model\n",
        "predictions = model.predict(img_array)\n",
        "\n",
        "# Get the predicted class label\n",
        "predicted_class_index = np.argmax(predictions[0])\n",
        "predicted_class_label = class_names[predicted_class_index]\n",
        "\n",
        "# Display the predicted class label\n",
        "print(\"Predicted class label:\", predicted_class_label)\n"
      ],
      "metadata": {
        "id": "if8aS7w3Cg_r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the class names\n",
        "class_names = ['actinic keratosis', 'seborrheic keratosis', 'basal cell carcinoma', 'nevus', 'squamous cell carcinoma', 'vascular lesion', 'dermatofibroma', 'pigmented benign keratosis', 'melanoma']\n",
        "\n",
        "#Path to the directory containing the test images\n",
        "test_data_dir = \"/content/gdrive/MyDrive/CNN/Skin_Cancer_Data/Test/melanoma\"\n",
        "\n",
        "#List all the image filenames in the directory\n",
        "image_files = os.listdir(test_data_dir)\n",
        "\n",
        "#Choose a random image from the directory\n",
        "random_image_file = random.choice(image_files)\n",
        "\n",
        "#Load the image and preprocess it\n",
        "img_path = os.path.join(test_data_dir, random_image_file)\n",
        "img = image.load_img(img_path, target_size=(img_height, img_width))\n",
        "\n",
        "#Display the chosen picture\n",
        "plt.imshow(img)\n",
        "plt.axis('off')\n",
        "plt.title('Chosen Picture')\n",
        "plt.show()\n",
        "\n",
        "##Convert the image to a NumPy array\n",
        "img_array = image.img_to_array(img)\n",
        "img_array = np.expand_dims(img_array, axis=0)\n",
        "img_array /= 255.0 # Normalize the image\n",
        "\n",
        "#Make predictions using the trained model\n",
        "predictions = model.predict(img_array)\n",
        "\n",
        "#Get the predicted class label\n",
        "predicted_class_index = np.argmax(predictions[0])\n",
        "predicted_class_label = class_names[predicted_class_index]\n",
        "\n",
        "#Display the predicted class probabilities\n",
        "plt.bar(class_names, predictions[0])\n",
        "plt.title('Predicted Class Probabilities')\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel('Probability')\n",
        "plt.show()\n",
        "\n",
        "#Print the predicted class label\n",
        "print(\"Predicted class label:\", predicted_class_label)"
      ],
      "metadata": {
        "id": "MQ_Kic_aFHaz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hWFu5HzCNxky"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}